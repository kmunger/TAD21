df<-data.frame(years_all, generation)
years<-numeric()
Lost<-numeric()
Greatest<-numeric()
Silent<-numeric()
Boomer<-numeric()
GenX<-numeric()
Older<-numeric()
Millennial<-numeric()
i<-44
for(i in 1:length(unique(df$years_all))){
active<-filter(df, years_all == unique(df$years_all)[i])
years<-c(years, unique(df$years_all)[i])
Older<-c(Older, sum(active$generation == "Old Af") / length(active$generation))
Lost<-c(Lost, sum(active$generation == "Lost") / length(active$generation))
Greatest<-c(Greatest, sum(active$generation == "Greatest") / length(active$generation))
Silent<-c(Silent, sum(active$generation == "Silent") / length(active$generation))
Boomer<-c(Boomer, sum(active$generation == "Boomer") / length(active$generation))
GenX<-c(GenX, sum(active$generation == "GenX") / length(active$generation))
Millennial<-c(Millennial, sum(active$generation == "Millennial") / length(active$generation))
}
all_df<-data.frame(years,Greatest, Silent, Boomer, GenX, Millennial)
library(reshape2)
melted_data<-melt(all_df, id.vars = "years")
melted_data$age<-melted_data$years
melted_data$age[melted_data$variable == "Boomer"] <- melted_data$age[melted_data$variable == "Boomer"] - 1955
melted_data$age[melted_data$variable == "GenX"] <- melted_data$age[melted_data$variable == "GenX"] - 1972
melted_data$age[melted_data$variable == "Silent"] <- melted_data$age[melted_data$variable == "Silent"] - 1936
melted_data$age[melted_data$variable == "Millennial"] <- melted_data$age[melted_data$variable == "Millennial"] - 1988
melted_data$age[melted_data$variable == "Greatest"] <- melted_data$age[melted_data$variable == "Greatest"] - 1915
#melted_data$age[melted_data$variable == "Lost"] <- melted_data$age[melted_data$variable == "Lost"] - 1892
#melted_data$age[melted_data$variable == "Older"] <- melted_data$age[melted_data$variable == "Older"] - 1881
####
melted_data<-filter(melted_data, age > 24)
melted_data<-filter(melted_data, age < 100)
melted_data$age
melted_data<-melted_data %>% group_by(variable) %>%
mutate(last_value = last(age)) %>%  mutate(first_value = first(age))
p<-ggplot(melted_data, aes(x=age, y=value, group=variable,color=variable))+
geom_line(size=1.5) +
ylab("Share of Senate (%)")+xlab("Median Age") +theme_bw() +scale_x_continuous(limits=c(25, 98))
png(filename = "good_senate_lifecycle.png")
p+theme(legend.title = element_blank(),legend.justification=c(1,0), legend.position=c(1,0),legend.text = element_text( size = 18))
dev.off()
write.csv(file ="C:/Users/kevin/Dropbox/book/data/final_data/figure4_6.csv", x = melted_data)
p+theme(legend.title = element_blank(),legend.justification=c(1,0), legend.position=c(1,0),legend.text = element_text( size = 18))
write.csv(file ="C:/Users/kevin/Dropbox/book/data/final_data/figure4_6.csv", x = melted_data)
#################################Adjust for denominator!
##births
#####
silent_births<-47
boomer_births<-76
genx_births<-55
millennial_births<-62
greatest_births<-50
total<-silent_births + boomer_births + genx_births + millennial_births + greatest_births
##births + estimated population in 2019
#####
#silent_births<-47
#boomer_births<-76
#genx_births<-65
#millennial_births<-73
#total<-silent_births + boomer_births + genx_births + millennial_births
Silent1<-(Silent /silent_births)
Boomer1<-(Boomer /boomer_births)
GenX1<-(GenX /genx_births)
Millennial1<-(Millennial /millennial_births)
all_df_adjusted<-data.frame(years, Silent1, Boomer1, GenX1, Millennial1)
library(reshape2)
melted_data<-melt(all_df_adjusted, id.vars = "years")
melted_data$age<-melted_data$years
melted_data$age[melted_data$variable == "Boomer1"] <- melted_data$age[melted_data$variable == "Boomer1"] - 1955
melted_data$age[melted_data$variable == "GenX1"] <- melted_data$age[melted_data$variable == "GenX1"] - 1972
melted_data$age[melted_data$variable == "Silent1"] <- melted_data$age[melted_data$variable == "Silent1"] - 1936
melted_data$age[melted_data$variable == "Millennial1"] <- melted_data$age[melted_data$variable == "Millennial1"] - 1988
melted_data$age[melted_data$variable == "Greatest1"] <- melted_data$age[melted_data$variable == "Greatest1"] - 1915
#melted_data$age[melted_data$variable == "Lost"] <- melted_data$age[melted_data$variable == "Lost"] - 1892
#melted_data$age[melted_data$variable == "Older"] <- melted_data$age[melted_data$variable == "Older"] - 1881
####
melted_data<-filter(melted_data, age > 24)
melted_data<-filter(melted_data, age < 100)
melted_data$age
melted_data<-melted_data %>% group_by(variable) %>%
mutate(last_value = last(age)) %>%  mutate(first_value = first(age))
p<-ggplot(melted_data, aes(x=age, y=value, group=variable,color=variable))+
geom_line(size=1.5)+
ylab("Share of Senate (%)")+xlab("Median Age") +theme_bw() +scale_x_continuous(limits=c(25, 98))
png(filename = "good_senate_lifecycle_adjusted.png")
p+theme(legend.title = element_blank(),legend.justification=c(1,0), legend.position=c(1,0),legend.text = element_text( size = 18))
dev.off()
#####
setwd("C:/Users/kevin/Dropbox/book/data/")
#setwd("C:/Users/kmm7999/Dropbox/book/data/")
options(stringsAsFactors = FALSE)
##read in csv
mcs<-read.csv("rep_indicators.csv", stringsAsFactors = F)
mcs$birthyear<-as.numeric(substr(mcs$Birthday, 1, 4))
mcs<-filter(mcs, is.na(mcs$birthyear) == F)
now<-filter(mcs, X2021 == 1)
hist(now$birthyear)
table(now$birthyear)
###
congs<-seq(1935, 2021, 2)
setwd("C:/Users/kevin/Dropbox/book/graphs/hists/")
##############################Do it by ages
names(mcss)
i<-44
ages_all<-numeric()
years_all<-numeric()
mean_age<-numeric()
median_age<-numeric()
var_age<-numeric()
for(i in 1:length(congs)){
mcss<-mcs[,c(2:48)]
active<-mcss[, (2 + i)]
year_cong<-names(mcss)[(2 + i)]
year_cong<-as.numeric(substr(x = year_cong, 2, 5))
active<-as.logical(active)
years<-mcss[active,]
ages<-year_cong - years$birthyear
ages_all<-c(ages_all, ages)
years_all<-c(years_all, rep(year_cong, times = length(ages)))
mean_age<-c(mean_age, rep(mean(ages), times = length(ages)))
median_age<-c(median_age, rep(median(ages), times = length(ages)))
var_age<-c(var_age, rep(var(ages), times = length(ages)))
}
#df<-data.frame(ages_all, years_all, mean_age, median_age)
#library(ggplot2)
#library(magick)
#library(gganimate)
#library(png)
#library(gifski)
#p <- ggplot(df, aes(ages_all)) + geom_vline(xintercept = mean_age, color = 'red')+
# geom_vline(xintercept = median_age, color = 'blue')+
#geom_histogram(
#                fill = "transparent", colour = "gray10")+
#transition_time(years_all)+ theme_bw() +
#labs(title = 'Age Distribution of US House of Representatives in {frame_time}', x = 'Ages', y = 'Number of MCs')
#p
#anim<-animate(p)
#anim_save("MCs.gif", anim)
####need to drop all the y axes!!!!!!!!
hist(mean_age, xlab= "Mean Age", main = "Distribution of Mean Ages of MCs, 1935-2019", breaks = 10)
abline(v = mean_age[19144], col = "blue", lwd=3)
mcs_sum<-data.frame(mean_age, median_age, var_age)
write.csv(file ="C:/Users/kevin/Dropbox/book/data/final_data/figure4_4.csv", x = mcs_sum)
sessions<-mcs[, c(4:47)]
sessions_per_mc<-apply(X = sessions,1, FUN = sum)
weighted_birthyears<-numeric()
for(i in 1:length(sessions_per_mc)){
weighted_birthyears<-c(weighted_birthyears, rep(mcs$birthyear[i], sessions_per_mc[i]))
}
png(file = "full_hist_mcs.png")
hist(weighted_birthyears, breaks = 20,
xlab = "Birthyear", ylab="Sessions of Congress Served", main = "Sessions of Congress Served, by Birthyear, 1933-2019")
abline(h=435 * 5/2, lty = 2)
hist(weighted_birthyears, breaks = 20,
xlab = "Birthyear", ylab="Sessions of Congress Served", main = "Sessions of Congress Served, by Birthyear, 1933-2019")
abline(h=435 * 5/2, lty = 2)
dev.off()
png(file = "full_hist_mcs.png")
hist(weighted_birthyears, breaks = 20,
xlab = "Birthyear", ylab="Sessions of Congress Served", main = "Sessions of Congress Served, by Birthyear, 1933-2019")
abline(h=435 * 5/2, lty = 2)
dev.off()
hist(weighted_birthyears, breaks = 20,
xlab = "Birthyear", ylab="Sessions of Congress Served", main = "Sessions of Congress Served, by Birthyear, 1933-2019")
abline(h=435 * 5/2, lty = 2)
write.csv(file ="C:/Users/kevin/Dropbox/book/data/final_data/figure4_1.csv", x = weighted_birthyears)
setwd("C:/Users/kevin/Dropbox/book/data/")
mcs<-read.csv("sen_indicators.csv", stringsAsFactors = F)
mcs$birthyear<-as.numeric(substr(mcs$Birthday, 1, 4))
mcs<-filter(mcs, is.na(mcs$birthyear) == F)
###
congs[8]
congs<-seq(1935, 2021, 2)
setwd("C:/Users/kevin/Dropbox/book/graphs/hists/")
##############################Do it by ages
i<-1
ages_all<-numeric()
years_all<-numeric()
mean_age<-numeric()
median_age<-numeric()
var_age<-numeric()
i<-1
ages_all<-numeric()
years_all<-numeric()
mean_age<-numeric()
median_age<-numeric()
var_age<-numeric()
mcss<-mcs[,c(2:48)]
for(i in 1:length(congs)){
active<-mcss[, (2 + i)]
year_cong<-names(mcss)[(2 + i)]
year_cong<-as.numeric(substr(x = year_cong, 2, 5))
active<-as.logical(active)
years<-mcss[active,]
ages<-year_cong - years$birthyear
ages_all<-c(ages_all, ages)
years_all<-c(years_all, rep(year_cong, times = length(ages)))
mean_age<-c(mean_age, rep(mean(ages), times = length(ages)))
median_age<-c(median_age, rep(median(ages), times = length(ages)))
var_age<-c(var_age, rep(var(ages), times = length(ages)))
}
mcs_sum<-data.frame(mean_age, median_age, var_age)
write.csv(file ="C:/Users/kevin/Dropbox/book/data/final_data/figure4_7.csv", x = mcs_sum)
sessions<-mcs[, c(4:47)]
sessions_per_mc<-apply(X = sessions,1, FUN = sum)
weighted_birthyears<-numeric()
for(i in 1:length(sessions_per_mc)){
weighted_birthyears<-c(weighted_birthyears, rep(mcs$birthyear[i], sessions_per_mc[i]))
}
hist(weighted_birthyears, breaks = 20,
xlab = "Birthyear", ylab="Senate Terms Served", main = "Senate Terms Served, by Birthyear, 1933-2019")
abline(h = 5/6 *100 *3 , lty = 2)
write.csv(file ="C:/Users/kevin/Dropbox/book/data/final_data/figure4_5.csv", x = weighted_birthyears)
# NOTE: To load data, you must download both the extract's data and the DDI
# and also set the working directory to the folder with these files (or change the path below).
library(dplyr)
library(ggplot2)
if (!require("ipumsr")) stop("Reading IPUMS data into R requires the ipumsr package. It can be installed using the following command: install.packages('ipumsr')")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
if (!require("ipumsr")) stop("Reading IPUMS data into R requires the ipumsr package. It can be installed using the following command:
install.packages('ipumsr')")
install.packages('ipumsr')
require("ipumsr")
install.packages("haven")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
ddi <- read_ipums_ddi("atus_00004.xml")
library(foreign)
library(dplyr)
library(lubridate)
library(stringr)
#library(Weighted.Desc.Stat)
setwd("C:/Users/kevin/Dropbox/book/data/")
#setwd("C:/Users/kmm7999/Dropbox/book/data/")
options(stringsAsFactors = FALSE)
##read in csv
mcs<-read.csv("combined.csv", stringsAsFactors = F)
mcs$birthyear<-as.numeric(substr(mcs$Birthday, 1, 4))
#for(i 1:length(mcs$X))
mcs$year<-as.numeric(substr(mcs$release_date, start = 1, 4))
as.numeric(mcs$first5actors[1])
mcs$birthyears<-gsub("\\[", "", mcs$birthyr5)
mcs$birthyears<-gsub("\\]", "", mcs$birthyears)
mcs$birthyears<-gsub("\\'", "", mcs$birthyears)
mcs$birthyears<-gsub("\\,", "", mcs$birthyears)
mcs$birthyears<-gsub("\\N", "", mcs$birthyears)
mcs$birthyears<-gsub("no record", "", mcs$birthyears)
mcs$birthyears<-gsub("\\\\", "", mcs$birthyears)
actor_ages<-numeric()
years<-numeric()
for(i in 1:length(mcs$X)){
current_ages <- mcs$year[i] - as.numeric(strsplit(mcs$birthyears[i], " ")[[1]])
actor_ages<-c(actor_ages, current_ages )
years<-c(years, rep(mcs$year[i], length(current_ages)))
}
actor_df<-data.frame(ages = actor_ages, years = years)
actor_df<-filter(actor_df, is.na(actor_df$ages) == F )
total_years<-sort(unique(actor_df$years))
total_years<-total_years[total_years > 1921]
total_years<-total_years[total_years  < 2018]
rm(list = ls())
setwd("C:/Users/kevin/Documents/GitHub/TAD21/")
# Loading packages
#install.packages("factoextra")
library(quanteda)
library(factoextra)
library(dplyr)
## 1 PCA
# 1.1  function in base R for PCA:
# see: http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/118-principal-component-analysis-in-r-prcomp-vs-princomp/
?prcomp # uses the singular value decomposition approach: examines the covariances/correlations between individuals
# Remember to center your data! (default = TRUE) -- use scale() on your matrix beforehand, or the option in prcomp()
# And don't have any missing values!
# 1.2 Example
data("data_corpus_inaugural")
inaugural <- corpus_subset(data_corpus_inaugural, Year > "1900-01-01")
inaugural_dfm <- dfm(inaugural,
stem = T,
remove_punct = T,
remove = stopwords("english")
)
inaugural_mat <- convert(inaugural_dfm, to = "matrix") # convert to matrix
# run pca
inaugural_pca <- prcomp(inaugural_mat, center = TRUE, scale = TRUE)
# visualize eigenvalues (scree plot: shows percentage of variance explained by each dimension)
fviz_eig(inaugural_pca, addlabels = TRUE)
# Loadings for each variable: columns contain the eigenvectors
inaugural_pca$rotation[1:10, 1:5]
dim(inaugural_pca$rotation)
# Q: can we interpret the dimensions?
# top loadings on PC1
pc_loadings <- inaugural_pca$rotation
# what do we expect this correlation to be?
cor(pc_loadings[,1], pc_loadings[,2])  # these should be orthogonal
# token loadings
N <- 10
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,1])) %>% arrange(-loading)
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
# plot top tokens according to absolute loading values
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
# Value of the rotated data: your "new", dimensionality reduced data
View(inaugural_pca$x)  # each observation
# retrieve most similar documents
install.packages("text2vec")
library(text2vec)
# function computes cosine similarity between query and all documents and returns N most similar
nearest_neighbors <- function(query, low_dim_space, N = 5, norm = "l2"){
cos_sim <- sim2(x = low_dim_space, y = low_dim_space[query, , drop = FALSE], method = "cosine", norm = norm)
nn <- cos_sim <- cos_sim[order(-cos_sim),]
return(names(nn)[2:(N + 1)])  # query is always the nearest neighbor hence dropped
}
# apply to document retrieval
nearest_neighbors(query = "2009-Obama", low_dim_space = inaugural_pca$x, N = 5, norm = "l2")
rm(list = ls())
setwd("C:/Users/kevin/Documents/GitHub/TAD21/")
library(quanteda)
library(factoextra)
library(dplyr)
data("data_corpus_inaugural")
inaugural <- corpus_subset(data_corpus_inaugural, Year > "1900-01-01")
inaugural_dfm <- dfm(inaugural,
stem = T,
remove_punct = T,
remove = stopwords("english")
)
inaugural_mat <- convert(inaugural_dfm, to = "matrix") # convert to matrix
inaugural_pca <- prcomp(inaugural_mat, center = TRUE, scale = TRUE)
fviz_eig(inaugural_pca, addlabels = TRUE)
inaugural_pca$rotation[1:10, 1:5]
dim(inaugural_pca$rotation)
pc_loadings <- inaugural_pca$rotation
cor(pc_loadings[,1], pc_loadings[,2])  # these should be orthogonal
N <- 10
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,1])) %>% arrange(-loading)
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
View(inaugural_pca$x)  # each observation
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,2])) %>% arrange(-loading)
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
N <- 5
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,2])) %>% arrange(-loading)
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
N <- 3
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,2])) %>% arrange(-loading)
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
View(inaugural_pca$x)  # each observation
N <- 5
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,6])) %>% arrange(-loading)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
N <- 3
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,6])) %>% arrange(-loading)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
inaugural <- corpus_subset(data_corpus_inaugural, Year > "1980-01-01")
inaugural_dfm <- dfm(inaugural,
stem = T,
remove_punct = T,
remove = stopwords("english")
)
inaugural_mat <- convert(inaugural_dfm, to = "matrix") # convert to matrix
inaugural_pca <- prcomp(inaugural_mat, center = TRUE, scale = TRUE)
fviz_eig(inaugural_pca, addlabels = TRUE)
inaugural_pca$rotation[1:10, 1:5]
dim(inaugural_pca$rotation)
pc_loadings <- inaugural_pca$rotation
cor(pc_loadings[,1], pc_loadings[,2])  # these should be orthogonal
N <- 10
pc1_loading <- tibble(token = rownames(pc_loadings), loading = as.vector(pc_loadings[,1])) %>% arrange(-loading)
pc1_loading$loading <- scale(pc1_loading$loading, center = TRUE)
pc1_loading <- rbind(top_n(pc1_loading, N, loading),top_n(pc1_loading, -N, loading))
pc1_loading <- transform(pc1_loading, token = factor(token, levels = unique(token)))
ggplot(pc1_loading, aes(token, loading)) +
geom_bar(stat = "identity", fill = ifelse(pc1_loading$loading <= 0, "grey20", "grey70")) +
coord_flip() +
xlab("Tokens") + ylab("Tokens with Top Loadings on PC1") +
scale_colour_grey(start = .3, end = .7) +
theme(panel.background = element_blank(),
axis.text.x = element_text(size=16),
axis.text.y = element_text(size=16),
axis.title.y = element_text(size=18, margin = margin(t = 0, r = 15, b = 0, l = 15)),
axis.title.x = element_text(size=18, margin = margin(t = 15, r = 0, b = 15, l = 0)),
legend.text=element_text(size=16),
legend.title=element_blank(),
legend.key=element_blank(),
legend.position = "top",
legend.spacing.x = unit(0.25, 'cm'),
plot.margin=unit(c(1,1,0,0),"cm"))
